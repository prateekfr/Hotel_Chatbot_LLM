# ğŸ¨ Hotel Chatbot â€“ LLM Finetuned

## ğŸ“Œ Project Overview

This project aims to build a **domain-specific chatbot** that answers questions **only** based on knowledge scraped from a specific hotel chainâ€™s website (e.g., Taj Mahal Palace,Mumbai). The pipeline includes:
- **Web scraping**
- **Knowledge base creation**
- **Fine-tuning a Falcon-1B-Instruct model using QLoRA**
- **Streamlit-based interactive chat interface**

---

## DEMO VIDEO
- GDrive Link :- https://drive.google.com/file/d/1FItfaTaidGFfB6VOh6LRwH_RCuo3tc9G/view?usp=sharing

---


## ğŸš€ Features
- âš™ï¸ **Fine-tuned LLM (Falcon1B-Instruct)** with LoRA adapters and Quantizations
- ğŸ“„ Strictly domain-bound responses via fine-tuning 
- ğŸ’¬ Easy-to-use chatbot UI with Streamlit
- ğŸ“š Structured QA training using `.jsonl` knowledge base
- ğŸ•¸ï¸ Selenium + BeautifulSoup-based robust web scraper

---

## ğŸ“ Project Structure

```
Hotel_Chatbot_LLM/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ raw/ taj-mahal-palace-mumbai.json                 # Raw scraped content
â”‚   â””â”€â”€ processed/ processed_dataset.json,                # Cleaned text files per hotel
â”‚                   falcon_finetune_dataset.jsonl         # Instructions Based jsonl file
â”‚   â””â”€â”€ embeddings/rag_db                                 # ChromaDB Vector Files
â”œâ”€â”€ model/                                               # Fine Tuned Falcon Model
â”‚   â””â”€â”€ checkpoint-20/ 
â”‚   â””â”€â”€ checkpoint-20/
â”‚   â”œâ”€â”€ adapter_config.json
â”‚   â”œâ”€â”€ adapter_model.safetensors
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ special_tokens_map.json
â”‚   â”œâ”€â”€ tokenizer_config.json
â”‚   â””â”€â”€tokenizer.json
â”œâ”€â”€ offload/                                              #Offload Directory
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ 01_scraper.py               # Web scraper using Selenium + fake-useragent + BeautifulSoup
â”‚   â”œâ”€â”€ 02_preprocess.py            # Converts scraped data into instruction-tuned format
â”‚   â”œâ”€â”€ 03_instruct_dataset.py      # Converts scraped data into instruction-tuned format
â”‚   â”œâ”€â”€ 04_fine_tune.py             # LoRA fine-tuning script using HuggingFace Transformers
â”‚   â”œâ”€â”€ 05_inference.py             # Script for testing model responses
â”‚   â””â”€â”€ 06_rag_pipeline.py          # ChromaDB RAG pipeline
â”œâ”€â”€ app.py                          # Streamlit chat interface
â”œâ”€â”€ requirements.txt                # Dependencies 
â””â”€â”€ README.md

```

---

## ğŸ§  Model Details

- **Base Model**: `tiiuae/Falcon-1B-Instruct`
- **Fine-tuning Technique**:  QLoRA (using `peft`)
- **Tokenizer**: AutoTokenizer from HuggingFace
- **Training Format**:
  ```json
  {
    "text": "### Instruction:\n<QUESTION>\n\n### Response:\n<ANSWER>"
  }
  ```

---

## âš’ï¸ Setup Instructions

### 1. Clone the Repository
```bash
git clone https://github.com/yourusername/hotel-chatbot-llm.git
cd hotel-chatbot-llm
```

### 2. Create & Activate Virtual Environment
```bash
conda create -p venv python==3.10 -y
conda activate venv/
```

### 3. Install Dependencies
```bash
pip install -r requirements.txt
```

### 4. Scrape and Prepare Dataset
```bash
python scripts/01_scraper.py
python scripts/02_preprocess.py
python scripts/03_instruct.py
```

### 5. Fine-tune the Model
```bash
python scripts/04_fine_tune.py
```

### 6. Prepare VectorDB
```bash
python scripts/06_rag_pipeline.py
```

### 7. Launch Chatbot
```bash
streamlit run app.py
```
---

## ğŸ“Š Example Prompt Format

```
### Instruction:
What are the check-in and check-out timings at JW Marriott Bengaluru?

### Response:
Check-in time is from 3:00 PM, and check-out is until 12:00 PM.
```

---

## ğŸ’¡ Future Enhancements

- Better Knowledge Base with multiple hotels for no RAG approach
- Faster Retrival 
- Experiments with other LLM models for better results without hallucinations
- Using API keys not local installation of LLM

---

## ğŸ¤ Acknowledgements

- HuggingFace Transformers & PEFT
- Falcon-1B-Instruct from tiiuae
- Selenium + BeautifulSoup for scraping
- Streamlit for UI

---

